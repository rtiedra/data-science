{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68242da3-261d-4374-bebd-179c8411144e",
   "metadata": {},
   "source": [
    "<a id='librairies'></a>\n",
    "# Librairies Python\n",
    "Liste des librairies Python que l'on utilise:\n",
    "- la librairie [nltk](https://www.nltk.org/) (pour l'implémentation de méthodes NLP basiques)\n",
    "- la librairie [spaCy](https://pypi.org/project/spacy/) (pour l'implémentation de méthodes NLP avancées, dans 70+ langues et avec des [pipelines](https://spacy.io/models) pre-entrainés)\n",
    "- la librairie [numpy](https://numpy.org) (pour la manipulation de matrices et tables)\n",
    "- les fonctions [sent_tokenize](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html) et [word_tokenize](https://www.nltk.org/api/nltk.tokenize.word_tokenize.html) de nltk (pour la tokenisation d'un texte en phrases et en mots)\n",
    "- l'ensemble des stopwords français du sous-module français [spacy.lang.fr](https://github.com/explosion/spaCy/tree/master/spacy/lang/fr) de spaCy\n",
    "- la classe [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) (pour la conversion d'une collection de documents en une matrice de valeurs TF-IDF, avecc \"TF-IDF\" l'abbréviation pour [Term Frequency Inverse Document Frequency](https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd683bcf-03ed-4259-92dd-107fb0bbbe8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57450af9-184f-4b8f-9cd0-9e642c0cee2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Pour remplacer la commande de download \"nltk.download('punkt')\" procédant à un téléchargement depuis internet pas permis depuis tous les environnements, on doit installer manuellement le fichier \"punkt\" dans un répertoire. Dans le cas présent, on l'a fait dans:<br>\n",
    "<b>C:\\Users\\User\\miniconda3\\envs\\virtual-environment-name\\nltk_data\\tokenizers</b>\n",
    "\n",
    "La procédure générale d'installation de fichiers de la librairie nltk est décrite sur les sites:<br>\n",
    "https://www.nltk.org/data.html<br>\n",
    "https://stackoverflow.com/questions/40941761/i-am-having-trouble-downloading-nltks-punkt-tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e9c512-46e6-4681-b019-491b1fa81bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Les répertoires possibles d'installation des fichiers sont énumérés par la commande:\n",
    "\n",
    "# nltk.data.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba311d0-fc71-4cfa-996d-a19339a1bd04",
   "metadata": {},
   "source": [
    "Pour utiliser la librairie de NLP spaCy en français, il faut installer un pipeline pre-entrainé en français. Il y a plusieurs choix possibles, chacun avec une taille et une efficacité distincte, énumérés sur le site:<br>\n",
    "https://spacy.io/models/fr\n",
    "\n",
    "Par souci de simplicité en 1ère approche, on installe le pipeline le plus petit de 15 Mo, \"fr_core_news_sm\". A cause des interdictions de téléchargement depuis internet pas permis depuis certains environnements, il n'est pas toujours possible d'installer de manière automatique le pipeline. Il faut alors downloader le fichier \"fr_core_news_sm-3.5.0.tar.gz\", le placer dans le répertoire courant, et lancer la commande:<br>\n",
    "<b>pip install fr_core_news_sm-3.5.0.tar.gz</b>\n",
    "\n",
    "Les méthodes d'installation manuelle d'un pipeline spaCy sont par exemple décrites ici:<br>\n",
    "https://subscription.packtpub.com/book/data/9781800563353/2/ch02lvl1sec06/installing-spacy-s-statistical-models\n",
    "\n",
    "Quand tout cela est fait, on peut charger et donner un nom au pipeline en lançant la commande:<br>\n",
    "<b>nlp = spacy.load('fr_core_news_sm')</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2940a83-d612-4333-bfe8-1c0b4695f23c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chargement du pipeline français \"fr_core_news_sm\"\n",
    "\n",
    "nlp = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944de8f7-a5d8-4065-8b26-e2a92ba1a10e",
   "metadata": {},
   "source": [
    "<a id='Texte à résumer'></a>\n",
    "# Texte à résumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0556da9c-5e7b-4524-a3be-83782bea298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mTexte à résumer:\u001b[0m\n",
      "La mécanique quantique est la théorie mathématique et physique décrivant la structure et l'évolution dans le temps et l'espace des phénomènes physiques à l'échelle de l'atome et en dessous. Elle a été découverte lorsque les physiciens ont voulu décrire le comportement des atomes et les échanges d'énergie entre la lumière et la matière à cette échelle et dans tous les détails.\n",
      "\n",
      "Plusieurs noms lui sont associés, et en tout premier lieu Planck et Einstein, qui furent les premiers à comprendre que les échanges d'énergie lumineuse, puis l'énergie elle-même, ne pouvaient exister que sous forme quantifiée à l'occasion de leurs travaux sur le rayonnement du corps noir et l'effet photoélectrique. Bohr étendit les postulats quantiques de Planck et d'Einstein de la lumière à la matière, en proposant un modèle reproduisant le spectre de l'atome d'hydrogène.\n",
      "\n",
      "Pas à pas, des règles furent trouvées pour calculer les propriétés des atomes, des molécules et de leurs interactions avec la lumière lorsque, de 1925 à 1927, toute une série de travaux de plusieurs physiciens et mathématiciens donna corps à deux théories générales applicables à ces problèmes :\n",
      "\n",
      "- la mécanique ondulatoire de de Broglie et surtout de Schrödinger ;\n",
      "- la mécanique matricielle de Heisenberg, Born et Jordan.\n",
      "\n",
      "Ces deux mécaniques furent unifiées par Schrödinger du point de vue physique, et par von Neumann du point de vue mathématique. Enfin, Dirac formula la synthèse ou plutôt la généralisation complète de ces deux mécaniques, que l'on nomme aujourd'hui la mécanique quantique.\n",
      "\n",
      "La mécanique quantique, appliquée à des particules comme l'électron ou au champ électromagnétique à l'origine de la lumière, montre en réalité que ces deux objets ne sont ni vraiment des ondes ni vraiment des particules.\n",
      "\n",
      "Comme Einstein l'avait montré, l'énergie présente dans une onde lumineuse est en réalité sous forme de paquets discrets indivisibles, les photons. De même, les électrons présentent des aspects ondulatoires, comme de Broglie l'avait prédit, et on peut faire des expériences de diffraction et d'interférence avec eux. Cette situation est souvent résumée par le terme de « dualité onde-particule » pour la matière et la lumière, et on l'illustre par l'expérience des doubles fentes de Feynman, que l'on voit dans la vidéo ci-dessous.\n",
      "\n",
      "Niels Bohr a essayé de construire une interprétation physique rendant compte de cette étrange dualité : c'est la théorie de la complémentarité. Elle repose sur les inégalités de Heisenberg.\n",
      "\n",
      "Le cœur de la mécanique quantique repose sur l'utilisation d'amplitudes de probabilité pour caractériser tous les processus physiques possibles en mécanique quantique. Ce sont ces processus qui peuvent se propager sous forme d'onde, mais les grandeurs physiques associées à ces processus sont souvent quantifiées et donc discrètes. C'est le cas de l'énergie des électrons dans un atome.\n",
      "\n",
      "L'équation fondamentale de la mécanique quantique est l'équation de Schrödinger.\n",
      "\n",
      "Le monde quantique est étrange, le flou probabiliste y règne, et au fond, il indique une structure sous-jacente aux phénomènes qui est au-delà de l'espace et du temps. C'est ce que semblent montrer l'intrication quantique et l'effet EPR. L'émergence d'un monde classique à partir d'un monde quantique n'est toujours pas bien comprise. C'est un des objets de la théorie de la décohérence que d'expliquer cette émergence.\n"
     ]
    }
   ],
   "source": [
    "# On utilise comme exemple de texte un article sur la mécanique quantique, disponible sur le site:\n",
    "# https://www.futura-sciences.com/sciences/definitions/physique-mecanique-quantique-844/\n",
    "\n",
    "text = open('données/mécanique_quantique.txt','r', encoding='utf-8').read()\n",
    "print('\\x1B[4m' + 'Texte à résumer:' + '\\x1B[0m' '\\n' + text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b228daa-f42b-45b1-bb81-97615768e52e",
   "metadata": {},
   "source": [
    "<a id='Stopwords français'></a>\n",
    "# Stopwords français\n",
    "Dans cette section, on définit l'ensemble des stopwords français que l'on utilise. Dans une langue, les stopwords sont les mots les plus courants, sans grande signification, qu'il est préférable d'omettre lors d'une analyse NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ecae483-7c75-4f65-8f7e-13815338963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mEnsemble de stopwords français lemmatisés retenus:\u001b[0m\n",
      " {'oust', 'dix-neuf', 'dixième', 'nul', 'deux', 'apre', 'quatrième', 'rendre', 'dont', 'on', 'onze', 'chacun', 'hem', 'antérieur', 'dix', 'quatre-vingt', 'si', 'chaque', 'differente', 'dejer', 'pendant', 'mon', 'nous', 'semblable', 'reste', 'precisement', 'autrui', 'quel', 'chez', 'sien', 'quoiqu', 'sou', 'seize', 'celui', 'ouvert', '\\n\\n', 'ouvrir', 'ainsi', 'autre', 'ho', 'mais', 'nombreux', 'suivant', 'dit', 'différent', 'etais', 'lorsque', 'dever', 'celle', 'ne', \"'\", 'etaient', 'cent', 'se', 'jusqu', 'ha', 'moins', 'proceder', 'soi', 'quatorze', 'son', 's', 'hi', '^', 'different', 'hé', 'également', 'suffire', 'pour', 'as', 'envers', '`', 'plutôt', ';', 'ter', 'peu', 'vous', '-là', 'duquel', 'quant-à-soi', 'pre', ':', 'juste', '~', 'toucher', 'six', 'lui', 'celer', 'd', '@', 'na', 'celui-ci', 'devant', 'revoici', '$', 'suit', 'fai', 'environ', 'penser', 'combien', 'quiconqu', 'i', 'quatrièmement', 'lequel', 'c', 'où', 'auquel', 'sans', 'or', 'specifiqu', 'qu', 'maintenant', 't', 'eter', 'plutot', 'dehors', 'parfois', 'malgr', '|', 'souvent', 'douzième', 'septième', 'par', 'excepté', 'semblent', 'voici', '.', 'enfin', 'hep', 'treize', 'assez', 'etc', 'encore', 'eh', 'neuvième', 'egalement', '’', 'possible', 'quatre', 'huer', 'gens', 'voir', 'dedans', 'specifique', 'tant', 'selon', 'differer', 'douz', 'cinquantaine', 'cependant', 'tre', 'te', 'ah', 'tenir', 'revoilà', 'auxquelles', 'compris', 'vers', 'divers', 'entrer', 'attendre', 'pas', 'hou', 'comment', 'dix-huit', 'ce', '_', 'meme', 'malgré', 'moi', '#', 'derriere', 'da', 'cela', 'quinze', 'battre', 'tien', 'partir', 'dessous', 'plus', 'faire', 'huit', 'premièrement', 'aller', '&', '}', '-', 'seulement', 'abord', 'parce', ',', 'desormai', 'tel', 'alors', 'trois', 'vai', 'toujours', 'il', 'dans', 'l', 'surtout', 'notamment', 'très', 'quelque', 'â', 'tellemer', 'cinquième', 'quelconque', ']', 'delà', '/', 'cinq', 'sixième', 'desquelle', 'sauf', 'desquel', 'toi', 'voilà', 'suffit', 'je', ')', 'cinquantième', 'directe', 'avai', 'sur', 'etant', 'quoi', 'car', '!', 'parler', 'différents', 'derrière', 'afin', 'mien', 'etre', 'lors', 'voila', 'anterieur', 'durer', 'stop', 'savoir', 'et', '\"', '{', 'suivre', 'être', 'avant', 'hui', 'que', 'suffisant', 'une', 'soixant', 'n', 'mill', 'j', 'dessus', 'onzième', '%', 'laisser', 'ton', 'nôtre', 'notre', 'dire', 'base', 'seul', 'o', 'même', 'aupre', 'hors', 'néanmoins', 'quant', '«', 'moindre', 'votre', 'anterieure', 'taire', 'ouia', 'leur', 'précisemer', 'autrement', 'troisième', 'ceci', 'exactement', 'y', 'tendre', 'houp', 'hormi', 'certain', 'lui-même', 'avec', 'ou', 'spécifique', 'm', 'le', 'huitième', '»', 'façon', 'retour', 'vôtre', 'personne', 'préalable', 'en', 'puisqu', 'relatif', 'quarante', '<', 'sentir', 'ci', 'debout', '*', 'facon', 'deuxièmement', 'merci', 'troisièmement', '?', 'comme', 'plusieurs', 'avoir', 'revoila', 'déjà', 'près', 'sinon', 'permettre', 'relativement', 'depuis', 'ni', 'différente', 'parmi', 'certes', 'ö', 'là', 'dix-sept', 'devoir', 'désormais', 'effet', 'à', 'premier', 'outre', 'directement', 'pourquoi', 'qui', 'vingt', 'de', '(', '[', '>', 'maint', 'via', 'proche', 'quand', 'cinquante', 'peux', 'deuxième', 'donc', 'nouveau', 'tout', 'après', 'me', 'lès', 'pouvoir', 'auxquels', 'déja', 'tente', 'longtemps', 'è', 'luire', 'au', 'bas', 'dejà', 'dès', '+', 'concerner', 'sept', 'mienne', 'aussi', 'vé', '\\\\', 'neanmoins', 'rester', 'trente', 'allaient', 'importer', 'un', 'jusque', 'sembler', 'prealabl', '='}\n"
     ]
    }
   ],
   "source": [
    "# Liste des symboles de ponctuation que l'on considère\n",
    "\n",
    "list_punct = [\"'\", '’', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', '\\n\\n',\n",
    "              ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '«', '»']\n",
    "\n",
    "# Création d'une liste (et d'un ensemble) des stopwords constitué des stopwords français de spaCy + les ponctuations\n",
    "# On applique la lemmatisation de spaCy pour transformer les stopwords retenus dans leur forme \"racine\"\n",
    "# https://en.wikipedia.org/wiki/Lemmatisation\n",
    "\n",
    "string_stopwords = ' '.join(fr_stop)\n",
    "list_stopwords = [word.lemma_ for word in nlp(string_stopwords)] + list_punct\n",
    "set_stopwords = set(list_stopwords)\n",
    "\n",
    "print('\\x1B[4m' + 'Ensemble de stopwords français lemmatisés retenus:' + '\\x1B[0m' '\\n', set_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89387592-6ae8-4df3-b696-dc7ccfd082c1",
   "metadata": {},
   "source": [
    "<a id=\"Résumé extractif basé sur la matrice TF-IDF\"></a>\n",
    "# Résumé extractif basé sur la matrice TF-IDF\n",
    "\n",
    "Pour l'approche basée sur la matrice TF-IDF, on s'inspire du code du blog suivant, rédigé en collaboration avec un professeur de computer science de l'université de Jaén:<br>\n",
    "https://medium.com/saturdays-ai/building-a-text-summarizer-in-python-using-nltk-and-scikit-learn-class-tfidfvectorizer-2207c4235548\n",
    "\n",
    "Notre ajout principal par rapport au code initial est l'implémentation de la lemmatisation des mots en utilisant un pipeline pre-entrainé en français de spaCy + une amélioration de la vitesse de l'algorithme en utilisant des \"list comprehension\" plutôt que des boucles multiples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13363fb9-899f-4af4-8d1c-59c56ce1efc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# La fonction \"get_words\" détermine l'ensemble des mots du texte input \"text\" après lemmatisation\n",
    "\n",
    "def get_words(text):\n",
    "    return set([word.lemma_ for word in nlp(text)])\n",
    "\n",
    "# La fonction \"get_average\" calcule la moyenne des valeurs positives de la liste input \"values\"\n",
    "\n",
    "def get_average(values):\n",
    "    return np.mean([x for x in values if x > 0])\n",
    "\n",
    "# La fonction \"get_threshold\" calcule pour chaque phrase la moyenne des valeurs TF-IDF des mots de la phrase\n",
    "# Puis ensuite la moyenne des valeurs obtenues pour toutes les phrases, ceci en omettant les possibles valeurs vides \"NaN\"\n",
    "\n",
    "def get_threshold(tfidf_results):\n",
    "    l = tfidf_results.shape[0]\n",
    "    averages = [get_average(tfidf_results[i, :].toarray()[0]) for i in range(l)]\n",
    "    \n",
    "    return np.nanmean(averages)\n",
    "\n",
    "# La fonction \"summary_tf_idf\" génère le résumé du texte input à partir des phrases, matrice TF-IDF et handicap\n",
    "# La fonction sélectionne une phrase si la moyenne des valeurs TF-IDF des mots de la phrase est plus grande que la valeur threshold\n",
    "# La valeur threshold est égale à la valeur \"get_threshold(tfidf_results)\" multipliée par la valeur handicap\n",
    "# Plus l'handicap est grand, plus la valeur threshold est grande, et donc la sélection de la phrase moins probable\n",
    "# En particulier, si handicap=0 alors le résumé est égal à tout le texte input, et si handicap=+∞ alors le résumé est vide\n",
    "\n",
    "def summary_tf_idf(sentences, tfidf_results, handicap):\n",
    "    l = tfidf_results.shape[0]\n",
    "    threshold = get_threshold(tfidf_results) * handicap\n",
    "    summary_sentences = [sentences[i] for i in range(l) if get_average(tfidf_results[i, :].toarray()[0]) >= threshold]\n",
    "    \n",
    "    return ' '.join(summary_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0607b8-dd87-41b6-a6cc-1cb68cde1e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafael\\miniconda3\\envs\\venv_text_2\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Rafael\\miniconda3\\envs\\venv_text_2\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aupr', 'auxquelle', 'aver', 'battr', 'cinquant', 'dollar', 'luir', 'ouier', 'pourcent', 'pr', 'precisemer', 'revoiler', 'seiz', 'suffir', 'voiler'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mRésumé du texte avec handicap=0.90 basé sur l'approche TF-IDF:\u001b[0m\n",
      "Ces deux mécaniques furent unifiées par Schrödinger du point de vue physique, et par von Neumann du point de vue mathématique. Enfin, Dirac formula la synthèse ou plutôt la généralisation complète de ces deux mécaniques, que l'on nomme aujourd'hui la mécanique quantique. De même, les électrons présentent des aspects ondulatoires, comme de Broglie l'avait prédit, et on peut faire des expériences de diffraction et d'interférence avec eux. Elle repose sur les inégalités de Heisenberg. Le cœur de la mécanique quantique repose sur l'utilisation d'amplitudes de probabilité pour caractériser tous les processus physiques possibles en mécanique quantique. Ce sont ces processus qui peuvent se propager sous forme d'onde, mais les grandeurs physiques associées à ces processus sont souvent quantifiées et donc discrètes. C'est le cas de l'énergie des électrons dans un atome. L'équation fondamentale de la mécanique quantique est l'équation de Schrödinger. C'est ce que semblent montrer l'intrication quantique et l'effet EPR. L'émergence d'un monde classique à partir d'un monde quantique n'est toujours pas bien comprise. C'est un des objets de la théorie de la décohérence que d'expliquer cette émergence.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization du texte input en phrases\n",
    "# Création de la matrice TF-IDF avec le vocabulaire créé par fonction \"get_words\" et la liste de stopwords \"list_stopwords\"\n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "tfidf_results = TfidfVectorizer(tokenizer = get_words, stop_words = list_stopwords).fit_transform(sentences)\n",
    "\n",
    "# Lancement de la fonction \"summary_tf_idf\" pour générer un résumé du texte input étant donné ses phrases, matrice TF-IDF et handicap\n",
    "\n",
    "handicap = 0.9\n",
    "summary = summary_tf_idf(sentences, tfidf_results, handicap=handicap)\n",
    "\n",
    "# Print du résumé obtenu\n",
    "\n",
    "print('\\x1B[4m' + \"Résumé du texte avec handicap=%.2f basé sur l'approche TF-IDF:\" % handicap + '\\x1B[0m' '\\n' + summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krnl_venv_text_2",
   "language": "python",
   "name": "krnl_venv_text_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
